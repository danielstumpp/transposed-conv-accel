{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Operation (channels = 1, stride = 1, padding = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transposed_conv(X, K):\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] + h - 1, X.shape[1] + w - 1))\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            for ki in range(h):\n",
    "                for kj in range(w):\n",
    "                    Y[i + ki, j + kj] += X[i, j]*K[ki, kj]\n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  0.,  1.],\n",
      "        [ 0.,  4.,  6.],\n",
      "        [ 4., 12.,  9.]])\n",
      "tensor([[[[ 0.,  0.,  1.],\n",
      "          [ 0.,  4.,  6.],\n",
      "          [ 4., 12.,  9.]]]], grad_fn=<SlowConvTranspose2DBackward>)\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
    "K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
    "Y = transposed_conv(X, K)\n",
    "\n",
    "X, K = X.reshape(1, 1, 2, 2,), K.reshape(1, 1, 2, 2)\n",
    "tconv = nn.ConvTranspose2d(1, 1, kernel_size=2, bias=False)\n",
    "tconv.weight.data = K\n",
    "Y_gold = tconv(X)\n",
    "\n",
    "print(Y)\n",
    "print(Y_gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Matrix for Transposed Convolution           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dstum\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\dstum\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\dstum\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output size = s(n - 1) + k -2p<br/>\n",
    "\n",
    "s: stride<br/>\n",
    "n: input height/width<br/>\n",
    "k: kernel size<br/>\n",
    "p: padding<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_matrix(k,stride=1,input_size=128, padding=0):\n",
    "    op_size = stride*(input_size-1) + k.shape[1] - 2*padding\n",
    "    m_rows, m_cols = op_size, op_size\n",
    "    k_rows, k_cols = k.shape[1], k.shape[1]\n",
    "    \n",
    "    rows_out = m_rows - k_rows + 1\n",
    "    cols_out = m_cols - k_cols + 1\n",
    "    \n",
    "    v = np.zeros((rows_out*cols_out, m_rows, m_cols))\n",
    "    \n",
    "    for r in range(rows_out):\n",
    "        for c in range(cols_out):\n",
    "            for kr in range(k_rows):\n",
    "                for kc in range(k_cols):\n",
    "                    v[r * cols_out + c][r + kr, c + kc] = k[kr, kc]\n",
    "    \n",
    "    v = v.reshape((rows_out*cols_out), -1)\n",
    "    return v, op_size\n",
    "\n",
    "def column_vector(x):\n",
    "    return x.flatten().reshape(-1, 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 36)\n",
      "(36, 1)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "K = np.random.randint(1, 10, size=(3,3))\n",
    "X = np.random.randint(1,5, size = (6, 6))\n",
    "\n",
    "W, ops = conv_matrix(K,input_size=X.shape[0],padding=0, stride=1)\n",
    "X = column_vector(X)\n",
    "print(W.T.shape)\n",
    "print(X.shape)\n",
    "#Y = W.T @ X\n",
    "#Y = Y.reshape((ops, ops))\n",
    "\n",
    "#print(ops)\n",
    "#print(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14. 31. 25. 15.]\n",
      " [22. 37. 43. 29.]\n",
      " [12. 24. 43. 29.]\n",
      " [ 4.  8. 17.  7.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transposed Conv.\n",
    "\n",
    "output size = s(n - 1) + k -2p<br/>\n",
    "\n",
    "s: stride<br/>\n",
    "n: input height/width<br/>\n",
    "k: kernel size<br/>\n",
    "p: padding<br/>\n",
    "\n",
    "Increase p -> Decrease output size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "torch.Size([1, 1, 36, 36])\n",
      "torch.Size([1, 1, 36, 36])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(64).view(1,1,8,8)\n",
    "\n",
    "conv_t = nn.ConvTranspose2d(in_channels=1,\n",
    "                            out_channels=1,\n",
    "                            stride=5,\n",
    "                            kernel_size=(3,3),\n",
    "                            padding=1\n",
    "                            )\n",
    "op_padding = conv_t._output_padding(X,\n",
    "                       stride=conv_t.stride,\n",
    "                       padding=conv_t.padding,\n",
    "                       kernel_size=conv_t.kernel_size,\n",
    "                       output_size=None\n",
    "                       )\n",
    "print(op_padding)\n",
    "Y = nn.functional.conv_transpose2d(X,conv_t.weight, conv_t.bias, conv_t.stride, conv_t.padding, op_padding, conv_t.groups, conv_t.dilation)\n",
    "print(Y.size())\n",
    "print(conv_t(X).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "stride = 4\n",
    "ip_padding = 0\n",
    "op_padding = 1\n",
    "filter_size = 3\n",
    "input_size = 4\n",
    "\n",
    "# create input\n",
    "X = np.linspace(1, 16, 16).reshape((input_size, input_size))\n",
    "\n",
    "# create kernel\n",
    "K = np.ones((filter_size,filter_size))\n",
    "\n",
    "# get output size\n",
    "op_size = stride*(input_size-1) + filter_size - 2*ip_padding + op_padding\n",
    "\n",
    "# create output image init to zeros\n",
    "Y = np.zeros((op_size,op_size))\n",
    "\n",
    "for i in range(input_size):\n",
    "    for j in range(input_size):\n",
    "        for ki in range(filter_size):\n",
    "            for kj in range(filter_size):\n",
    "                \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _filter_to_mat(f):\n",
    "    \"\"\"\n",
    "    Converts a filter to matrix form\n",
    "    :param f: The filter (num_filters, depth, height, width)\n",
    "    :return: The matrix form of the filter which can be multiplied\n",
    "    \"\"\"\n",
    "    return f.reshape(f.shape[0], -1).T\n",
    "\n",
    "def _backward_im_to_rows(top_grad, inp_shape, filter_shape, dilation, stride, dilated_shape, res_shape):\n",
    "    \"\"\"\n",
    "    Gradient transformation for the im2rows operation\n",
    "    :param top_grad: The grad from the next layer\n",
    "    :param inp_shape: The shape of the input image\n",
    "    :param filter_shape: The shape of the filter (num_filters, depth, height, width)\n",
    "    :param dilation: The dilation for the filter\n",
    "    :param stride: The stride for the filter\n",
    "    :param dilated_shape: The dilated shape of the filter\n",
    "    :param res_shape: The shape of the expected result\n",
    "    :return: The reformed gradient of the shape of the image\n",
    "    \"\"\"\n",
    "    dilated_rows, dilated_cols = dilated_shape\n",
    "    num_rows, num_cols = res_shape\n",
    "    res = np.zeros(inp_shape, dtype=top_grad.dtype)\n",
    "    top_grad = top_grad.reshape(\n",
    "        (top_grad.shape[0], top_grad.shape[1], filter_shape[1], filter_shape[2], filter_shape[3]))\n",
    "    for it in range(num_rows * num_cols):\n",
    "        i = it // num_rows\n",
    "        j = it % num_rows\n",
    "        res[:, :, i * stride[0]:i * stride[0] + dilated_rows:dilation,\n",
    "            j * stride[1]:j * stride[1] + dilated_cols:dilation] += top_grad[:, it, :, :, :]\n",
    "    return res\n",
    "\n",
    "def transposed_conv2d(image, filters, dilation, stride):\n",
    "    \"\"\"\n",
    "    Perform a transposed convolution, which can upscale the image.\n",
    "    :param image: The input image to upscale\n",
    "    :param filters: The filters for this operation\n",
    "    :param dilation: The dilation factor for the filters\n",
    "    :param stride: The stride for the *forward* convolution\n",
    "    :return: The return upscaled image\n",
    "    \"\"\"\n",
    "    filter_shape = filters.shape\n",
    "    im_shape = image.shape\n",
    "    dilated_shape = ((filter_shape[2] - 1) * dilation + 1,\n",
    "                     (filter_shape[3] - 1) * dilation + 1)\n",
    "    res_shape = (im_shape[2] - 1) * stride[0] + \\\n",
    "        dilated_shape[0], (im_shape[3] - 1) * stride[1] + dilated_shape[1]\n",
    "    image_mat = image.reshape(\n",
    "        (image.shape[0], image.shape[1], -1)).transpose((0, 2, 1))\n",
    "    filtmat = _filter_to_mat(filters)\n",
    "    res_mat = image_mat.dot(filtmat.T)\n",
    "    return _backward_im_to_rows(res_mat, (image.shape[0], filters.shape[1], *res_shape), filters.shape, dilation,\n",
    "                                stride, dilated_shape, im_shape[2:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-d2ccafcc092b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransposed_conv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-69-79f1546b3414>\u001b[0m in \u001b[0;36mtransposed_conv2d\u001b[1;34m(image, filters, dilation, stride)\u001b[0m\n\u001b[0;32m     44\u001b[0m     dilated_shape = ((filter_shape[2] - 1) * dilation + 1,\n\u001b[0;32m     45\u001b[0m                      (filter_shape[3] - 1) * dilation + 1)\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[0mres_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mim_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[0mdilated_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mim_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdilated_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     image_mat = image.reshape(\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "X = torch.rand(64).view(1,1,8,8)\n",
    "\n",
    "conv_t = nn.ConvTranspose2d(in_channels=1,\n",
    "                            out_channels=1,\n",
    "                            stride=5,\n",
    "                            kernel_size=(3,3),\n",
    "                            padding=1\n",
    "                            )\n",
    "conv_t.weight = torch.nn.Parameter(torch.ones_like(conv_t.weight))\n",
    "conv_t(X)\n",
    "\n",
    "K = torch.ones((1,1,3,3))\n",
    "Y = transposed_conv2d(image=X, filters=K, dilation=0, stride=1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7ccb67de7081a05f54dc297e18d4107ab1f61dedc55f288c5f31e7d83840b6d4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
